{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c42376-048d-4059-ba5b-290fb150b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "from skorch.regressor import NeuralNetRegressor\n",
    "from skorch.dataset import ValidSplit\n",
    "from skorch.callbacks import EarlyStopping\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Sigmoid, ReLU\n",
    "from torch.nn import Module\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import euclidean\n",
    "from torch import tensor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from model import MLP\n",
    "import random\n",
    "from skorch.callbacks import EarlyStopping, LRScheduler, Freezer, Unfreezer\n",
    "from torch.optim.lr_scheduler import CyclicLR, ReduceLROnPlateau\n",
    "from skorch.regressor import NeuralNetRegressor, NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fa2b55-3ddf-42b5-af18-2204ca288d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_members = 3   \n",
    "query_number = 25          # The number of the AL Iterations in each Exp\n",
    "iteration = 20             # Total number of the Exps\n",
    "batch_size = 10\n",
    "total_initail_size = 9\n",
    "initial_size = 5\n",
    "\n",
    "seed_rf = np.load(file=\"..\\..\\Seeds\\seed2.npy\")\n",
    "seed_initial = np.load(file=\"..\\..\\Seeds\\seed3.npy\")\n",
    "\n",
    "seed_nn1 = np.load(file=\"..\\..\\Seeds\\seed4.npy\")\n",
    "seed_nn2 = np.load(file=\"..\\..\\Seeds\\seed5.npy\")\n",
    "seed_nn3 = np.load(file=\"..\\..\\Seeds\\seed6.npy\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4b4d3e-a21a-47b0-a67e-620b60531efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Committee_Prediction(learner_list, X_test, y_test):\n",
    "    initial_pred=[]\n",
    "    for i in learner_list:\n",
    "        initial_pred.append(r2_score(y_test, i.predict(X_test)))\n",
    "    initial_pred=np.array(initial_pred)\n",
    "    \n",
    "    return initial_pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a6b97c-6b0a-44e6-b09f-092d5a7b2b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_committee(learner_list, used_data, used_label):\n",
    "    new_list = []\n",
    "    for l in learner_list:\n",
    "        jdx = np.random.choice(np.arange(used_data.shape[0]), used_data.shape[0], replace=True)\n",
    "        l = l.fit(used_data[jdx], used_label[jdx])\n",
    "        new_list.append(l)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42eef26-ae57-4967-82fe-cdcfc19e5463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_argmax(values, n_instances):\n",
    "\n",
    "    assert n_instances <= values.shape[0], 'n_instances must be less or equal than the size of utility.'\n",
    "\n",
    "    max_idx = np.argpartition(-values, n_instances-1, axis=0)[:n_instances]\n",
    "    return max_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc25fb66-b970-4f6d-841b-611b12c8344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_QBC(unlebeled_samples, learner_list, n_instances=batch_size):\n",
    "    initial_pred=np.empty(shape=(n_members, unlebeled_samples.shape[0]))\n",
    "    for i in range(n_members):\n",
    "        initial_pred[i,:] = learner_list[i].predict(unlebeled_samples).reshape(1, -1)\n",
    "    std = np.var(initial_pred, axis=0)\n",
    "    return multi_argmax(std, n_instances=n_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfde7e20-f699-46f3-bc85-c16e5f498323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function(query_number, iters):\n",
    "# For saving results:\n",
    "    rf_model_training_r2 = []\n",
    "    rf_model_training_mse = []\n",
    "    rf_model_testing_r2 = []\n",
    "    rf_model_testing_mse = []\n",
    "    \n",
    "    # Number of member in committee:\n",
    "    learner_list = []\n",
    "    \n",
    "    # The model for evaluation:\n",
    "    rf_model = RandomForestRegressor(random_state=seed_rf[iters], n_estimators=100)\n",
    "    \n",
    "    # Load the data:\n",
    "    name1 = \"..\\..\\Datasets\\AutoMPG\\X_train\" + str(iters) + \".npy\"\n",
    "    name2 = \"..\\..\\Datasets\\AutoMPG\\X_test\" + str(iters) + \".npy\"\n",
    "    name3 = \"..\\..\\Datasets\\AutoMPG\\y_train\" + str(iters) + \".npy\"\n",
    "    name4 = \"..\\..\\Datasets\\AutoMPG\\y_test\" + str(iters) + \".npy\"\n",
    "    \n",
    "    X_train = np.load(name1, allow_pickle=True).astype(np.float32)\n",
    "    X_test = np.load(name2, allow_pickle=True).astype(np.float32)\n",
    "    y_train = np.load(name3, allow_pickle=True).astype(np.float32).reshape(-1, 1)\n",
    "    y_test = np.load(name4, allow_pickle=True).astype(np.float32).reshape(-1, 1)\n",
    "    \n",
    "    # Feature Dim\n",
    "    X = X_train.shape[1]\n",
    "    # The unlabeled pool\n",
    "    X_index = np.arange(X_train.shape[0])\n",
    "    \n",
    "    # Queried samples and labels\n",
    "    used_data = np.empty(shape=(0, X))\n",
    "    used_label = np.empty(shape=(0)).reshape(-1, 1)\n",
    "    \n",
    "    # Initial samples and labels\n",
    "    X_initial = np.empty(shape=(0,X))\n",
    "    y_initial = np.empty(shape=(0)).reshape(-1, 1)\n",
    "\n",
    "    # Initial Stage 1:\n",
    "    np.random.seed(seed_initial[iters])\n",
    "    idx = np.random.choice(range(len(X_index)), size=initial_size, replace=False)\n",
    "    train_idx = X_index[idx]\n",
    "\n",
    "    X_initial = X_train[train_idx]\n",
    "    y_initial = y_train[train_idx].reshape(-1, 1)\n",
    "\n",
    "    used_data = np.append(used_data, X_initial, axis=0).astype(np.float32)\n",
    "    used_label = np.append(used_label, y_initial, axis=0).astype(np.float32).reshape(-1, 1)\n",
    "    X_index = np.delete(X_index, idx, axis=0)\n",
    "    \n",
    "    # Initial Sagte 2:\n",
    "    rest_initial_X = np.empty(shape=(0,X))\n",
    "    rest_initial_y = np.empty(shape=(0)).reshape(-1, 1)\n",
    "    \n",
    "    np.random.seed(seed_initial[iters])\n",
    "    idx = np.random.choice(range(len(X_index)), size=total_initail_size-initial_size, replace=False)\n",
    "    train_idx = X_index[idx]\n",
    "    \n",
    "    rest_initial_X = np.append(rest_initial_X, X_train[train_idx], axis=0).astype(np.float32)\n",
    "    rest_initial_y = np.append(rest_initial_y, y_train[train_idx], axis=0).astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "    X_index = np.delete(X_index, idx, axis=0)\n",
    "    \n",
    "    used_data = np.append(used_data, rest_initial_X, axis=0).astype(np.float32)\n",
    "    used_label = np.append(used_label, rest_initial_y, axis=0).astype(np.float32).reshape(-1, 1)\n",
    "    \n",
    "    # Finished the Initialization Stages:\n",
    "    # RF Regressor for evaluation:\n",
    "    rf_model.fit(used_data, used_label.ravel())\n",
    "    # Training Scores:\n",
    "    rf_training_r2 = r2_score(used_label, rf_model.predict(used_data))\n",
    "    rf_training_mse = mean_squared_error(used_label, rf_model.predict(used_data))\n",
    "    rf_model_training_r2.append(rf_training_r2)\n",
    "    rf_model_training_mse.append(rf_training_mse)\n",
    "    \n",
    "    # Test Scores:\n",
    "    rf_model_r2 = r2_score(y_test, rf_model.predict(X_test))\n",
    "    rf_model_mse = mean_squared_error(y_test, rf_model.predict(X_test))\n",
    "    rf_model_testing_r2.append(rf_model_r2)\n",
    "    rf_model_testing_mse.append(rf_model_mse)\n",
    "    \n",
    "    print(\"After Initialization RF R2:\", rf_model_r2)\n",
    "\n",
    "    used_data = torch.from_numpy(used_data).to(device)\n",
    "    used_label = torch.from_numpy(used_label).to(device)\n",
    "    for member_idx in range(n_members):\n",
    "        \n",
    "        if member_idx == 0:\n",
    "            np.random.seed(seed_nn1[iters])\n",
    "            torch.manual_seed(seed_nn1[iters])\n",
    "        if member_idx == 1:\n",
    "            np.random.seed(seed_nn2[iters])\n",
    "            torch.manual_seed(seed_nn2[iters])\n",
    "        if member_idx == 2:\n",
    "            np.random.seed(seed_nn3[iters])\n",
    "            torch.manual_seed(seed_nn3[iters])\n",
    "            \n",
    "        regressor = NeuralNetRegressor(\n",
    "                                   MLP(X),\n",
    "                                   criterion=MSELoss(),\n",
    "                                   optimizer=torch.optim.Adam,\n",
    "                                   verbose=0,\n",
    "                                   max_epochs=100,\n",
    "                                   lr=0.001,\n",
    "                                   # Used for the batch AL\n",
    "                                   callbacks=[EarlyStopping(patience=20), ('lr_scheduler', LRScheduler(policy=ReduceLROnPlateau))],\n",
    "                                   train_split=ValidSplit(cv=5),\n",
    "                                   warm_start=False,\n",
    "                                   device='cuda',\n",
    "                                   batch_size = 200\n",
    "                                   )\n",
    "        jdx = np.random.choice(np.arange(used_data.shape[0]), used_data.shape[0], replace=True)\n",
    "        regressor.fit(used_data[jdx], used_label[jdx])\n",
    "        learner_list.append(regressor)\n",
    "\n",
    "    print(\"NN Test R2 after Initialization\", Committee_Prediction(learner_list, X_test, y_test))\n",
    "    print('NN R2', Committee_Prediction(learner_list, X_test, y_test))\n",
    "\n",
    "    for idx in range(query_number):\n",
    "        print('Query no. %d' % (idx+1))\n",
    "\n",
    "        idx = query_QBC(X_train[X_index], learner_list, n_instances=batch_size)\n",
    "\n",
    "        # Query the new sample:\n",
    "        X_train_index = X_index[idx]\n",
    "\n",
    "        new_X = X_train[X_train_index].reshape(batch_size, -1)\n",
    "        new_y = y_train[X_train_index].reshape(batch_size, -1)\n",
    "\n",
    "        # Adding the used data to the used_data pool\n",
    "        used_data = used_data.cpu().numpy()\n",
    "        used_label = used_label.cpu().numpy()\n",
    "        used_data = np.append(used_data, new_X, axis=0).astype(np.float32)\n",
    "        used_label = np.append(used_label, new_y, axis=0).astype(np.float32).reshape(-1, 1)\n",
    "        \n",
    "        # RF Evaluation\n",
    "        rf_model.fit(used_data, used_label.ravel())\n",
    "        \n",
    "        # Training Evaluation:\n",
    "        rf_training_r2 = r2_score(used_label, rf_model.predict(used_data))\n",
    "        rf_training_mse = mean_squared_error(used_label, rf_model.predict(used_data))\n",
    "        rf_model_training_r2.append(rf_training_r2)\n",
    "        rf_model_training_mse.append(rf_training_mse)\n",
    "        \n",
    "        # Test Evaluation:\n",
    "        rf_model_r2 = r2_score(y_test, rf_model.predict(X_test))\n",
    "        rf_model_mse = mean_squared_error(y_test, rf_model.predict(X_test))\n",
    "        rf_model_testing_r2.append(rf_model_r2)\n",
    "        rf_model_testing_mse.append(rf_model_mse)\n",
    "        \n",
    "        print(np.unique(used_data, axis=0).shape)\n",
    "        print(\"RF R2:\", rf_model_r2)\n",
    "        print(\"Remaining:\", X_index.shape[0])\n",
    "\n",
    "        # remove queried instance from pool\n",
    "        X_index = np.delete(X_index, idx, axis=0)\n",
    "        \n",
    "        used_data = torch.from_numpy(used_data).to(device)\n",
    "        used_label = torch.from_numpy(used_label).to(device)\n",
    "        \n",
    "        # Retrain the committee:\n",
    "        # for l in learner_list:\n",
    "        #     jdx = np.random.choice(np.arange(used_data.shape[0]), used_data.shape[0], replace=True)\n",
    "        #     l.fit(used_data[jdx], used_label[jdx])  \n",
    "        learner_list = retrain_committee(learner_list, used_data, used_label)\n",
    "            \n",
    "        # print('NN R2', Committee_Prediction(learner_list, X_test, y_test))\n",
    "    \n",
    "    rf_model_testing_r2 = np.array(rf_model_testing_r2)\n",
    "    rf_model_testing_mse = np.array(rf_model_testing_mse)\n",
    "    rf_model_training_r2 = np.array(rf_model_training_r2)\n",
    "    rf_model_training_mse = np.array(rf_model_training_mse)\n",
    "\n",
    "    # Used_data and Unsed_label:\n",
    "    used_data = used_data.cpu().numpy()\n",
    "    used_label = used_label.cpu().numpy()\n",
    "    np.save(file=\"..\\..\\Results\\Res_AutoMPG\\QBC\\Summary\\\\used_data\" + str(iters) + \".npy\", arr=used_data)\n",
    "    np.save(file=\"..\\..\\Results\\Res_AutoMPG\\QBC\\Summary\\\\used_labels\" + str(iters) + \".npy\", arr=used_label)\n",
    "\n",
    "    np.save(file=\"..\\..\\Results\\Res_AutoMPG\\QBC\\Summary\\\\testing_rf_r2_\" + str(iters) + \".npy\", arr=rf_model_testing_r2)\n",
    "    np.save(file=\"..\\..\\Results\\Res_AutoMPG\\QBC\\Summary\\\\testing_rf_mse_\" + str(iters) + \".npy\", arr=rf_model_testing_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37ea35d-6803-4cfa-8923-500e0465578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(iteration):\n",
    "    print(\"The Iteration is \", i)\n",
    "    main_function(query_number, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
